{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c2d3aa-0560-4e31-9b84-d185ebbaa97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eee0eb8-33c8-4e02-9e05-ae482f09de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd41afbb-dd08-4f26-a307-69137dd90e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data directories and model\n",
    "new_test_frames_path = \"/Users/eshitasuri/Desktop/Frames/test\"\n",
    "model_filename = 'incremental_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a2080a-d50c-45c2-b8cd-721694875789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_color_histogram(image):\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def calculate_brightness(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "    return brightness\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    contrast = l.std()\n",
    "    return contrast\n",
    "\n",
    "def calculate_edge_density(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    edge_density = np.mean(edges)\n",
    "    return edge_density\n",
    "\n",
    "def calculate_color_moments(image):\n",
    "    moments = cv2.moments(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    return hu_moments\n",
    "\n",
    "def extract_lbp(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = np.zeros_like(gray)\n",
    "    for i in range(1, gray.shape[0] - 1):\n",
    "        for j in range(1, gray.shape[1] - 1):\n",
    "            center = gray[i, j]\n",
    "            binary_string = ''\n",
    "            binary_string += '1' if gray[i - 1, j - 1] > center else '0'\n",
    "            binary_string += '1' if gray[i - 1, j] > center else '0'\n",
    "            binary_string += '1' if gray[i - 1, j + 1] > center else '0'\n",
    "            binary_string += '1' if gray[i, j + 1] > center else '0'\n",
    "            binary_string += '1' if gray[i + 1, j + 1] > center else '0'\n",
    "            binary_string += '1' if gray[i + 1, j] > center else '0'\n",
    "            binary_string += '1' if gray[i + 1, j - 1] > center else '0'\n",
    "            binary_string += '1' if gray[i, j - 1] > center else '0'\n",
    "            lbp[i, j] = int(binary_string, 2)\n",
    "    return lbp.flatten()\n",
    "\n",
    "def extract_hog(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    h, _ = hog(gray, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "    return h.flatten()\n",
    "\n",
    "def calculate_optical_flow(prev_image, next_image):\n",
    "    prev_gray = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_image, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    return mag.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42006cb-8714-4124-8b62-01e8b13f7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    histograms = []\n",
    "    brightness = []\n",
    "    contrast = []\n",
    "    edge_density = []\n",
    "    histogram_moments = []\n",
    "    lbp = []\n",
    "    hog_features = []\n",
    "    optical_flow = []\n",
    "\n",
    "    for img in images:\n",
    "        histograms.append(calculate_color_histogram(img))\n",
    "        brightness.append(calculate_brightness(img))\n",
    "        contrast.append(calculate_contrast(img))\n",
    "        edge_density.append(calculate_edge_density(img))\n",
    "        histogram_moments.append(calculate_color_moments(img))\n",
    "        lbp.append(extract_lbp(img))\n",
    "        hog_features.append(extract_hog(img))\n",
    "        optical_flow.append(calculate_optical_flow(img, img))  \n",
    "\n",
    "    features = np.hstack([\n",
    "        np.array(histograms),\n",
    "        np.array(brightness)[:, np.newaxis],\n",
    "        np.array(contrast)[:, np.newaxis],\n",
    "        np.array(edge_density)[:, np.newaxis],\n",
    "        np.array(histogram_moments),\n",
    "        np.array(lbp),\n",
    "        np.array(hog_features),\n",
    "        np.array(optical_flow)\n",
    "    ])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f59cd30f-3fbf-4d61-b08b-a37489f6333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, batch_size):\n",
    "    images = []\n",
    "    filenames = os.listdir(folder)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        if len(images) == batch_size or i == len(filenames) - 1:\n",
    "            yield images, filenames[i-batch_size+1:i+1]  # Yield the batch of images and their filenames\n",
    "            images = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678deae3-7bbc-4f44-a287-885e43a4099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and extract features for the test data\n",
    "def process_test_data(folder_path, batch_size):\n",
    "    all_features = []\n",
    "    selected_filenames = []\n",
    "    batch_number = 1\n",
    "    for batch, filenames in load_images_from_folder(folder_path, batch_size):\n",
    "        logging.info(f\"Processing batch {batch_number}\")\n",
    "        features = extract_features(batch)\n",
    "        all_features.append(features)\n",
    "        selected_filenames.extend(filenames)\n",
    "        batch_number += 1\n",
    "    all_features_df = pd.DataFrame(np.vstack(all_features))\n",
    "    return all_features_df, selected_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0558eb87-26bb-4f6a-9124-22e09c1bf41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 15:53:05,960 - INFO - Loading the model\n",
      "/Users/eshitasuri/anaconda3/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SGDClassifier from version 1.5.1 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "logging.info(\"Loading the model\")\n",
    "model = load(model_filename)\n",
    "\n",
    "# Number of frames to sample for testing\n",
    "sample_size = 2000\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617c803b-f2c4-44e6-ad46-ca8904106bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 15:53:09,945 - INFO - Extracting features from test data\n",
      "2024-08-01 15:53:09,951 - INFO - Processing batch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features from test data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_features_df, selected_filenames \u001b[38;5;241m=\u001b[39m process_test_data(new_test_frames_path, batch_size)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Impute and scale the features\u001b[39;00m\n\u001b[1;32m      5\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mprocess_test_data\u001b[0;34m(folder_path, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, filenames \u001b[38;5;129;01min\u001b[39;00m load_images_from_folder(folder_path, batch_size):\n\u001b[1;32m      7\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     features \u001b[38;5;241m=\u001b[39m extract_features(batch)\n\u001b[1;32m      9\u001b[0m     all_features\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[1;32m     10\u001b[0m     selected_filenames\u001b[38;5;241m.\u001b[39mextend(filenames)\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     18\u001b[0m     hog_features\u001b[38;5;241m.\u001b[39mappend(extract_hog(img))\n\u001b[1;32m     19\u001b[0m     optical_flow\u001b[38;5;241m.\u001b[39mappend(calculate_optical_flow(img, img))  \u001b[38;5;66;03m# Assuming optical flow between frames\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([\n\u001b[1;32m     22\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(histograms),\n\u001b[1;32m     23\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(brightness)[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m     24\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(contrast)[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m     25\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(edge_density)[:, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m     26\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(histogram_moments),\n\u001b[1;32m     27\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(lbp),\n\u001b[1;32m     28\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(hog_features),\n\u001b[1;32m     29\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(optical_flow)\n\u001b[1;32m     30\u001b[0m ])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/shape_base.py:368\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arrs \u001b[38;5;129;01mand\u001b[39;00m arrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "logging.info(\"Extracting features from test data\")\n",
    "test_features_df, selected_filenames = process_test_data(new_test_frames_path, batch_size)\n",
    "\n",
    "# Impute and scale the features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "test_features_imputed = imputer.fit_transform(test_features_df)\n",
    "test_features_scaled = scaler.fit_transform(test_features_imputed)\n",
    "\n",
    "# Predict on the test data\n",
    "logging.info(\"Predicting on test data\")\n",
    "predictions = model.predict(test_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f73f05-88cc-40bd-9047-c1281206e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute and scale the features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "test_features_imputed = imputer.fit_transform(test_features_df)\n",
    "test_features_scaled = scaler.fit_transform(test_features_imputed)\n",
    "\n",
    "# Predict on the test data\n",
    "logging.info(\"Predicting on test data\")\n",
    "predictions = model.predict(test_features_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "report = classification_report(true_labels, predictions)\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610231b-e3c9-47cd-a0d4-f764b5065fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aa3b7-280d-46cf-81f3-cf765b40a07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4386c-3f87-44fc-b730-fb135f3e12ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab280ed-72a0-4dbf-92d0-998522ed82df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
